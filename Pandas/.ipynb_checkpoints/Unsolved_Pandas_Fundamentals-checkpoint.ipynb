{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Pandas is a data analysis library for python that enables powerful and easy ingress, manipulation, and storage of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas as a dependency.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Structures\n",
    "Pandas features two major data structures: Series and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "Series objects are indexed, one-dimensional arrays that behave similar to native python lists, as well as featuring several methods native to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A native python list\n",
    "my_data = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"h\",\"i\",\"j\"]\n",
    "\n",
    "# Conversion to Pandas Series object\n",
    "my_series = pd.Series(my_data)\n",
    "\n",
    "# OPTIONAL: Naming our series\n",
    "my_series.name = \"My Letters\"\n",
    "\n",
    "# Printing out our Series\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Left, the series index is visible, starting from 0. To the right is the data we created in our list. At the bottom, we can see the optional name we added to the series, as well as the datatype of the data within the series.\n",
    "\n",
    "While this may not seem terribly impressive compared to a normal python list, this allows us to then use special pandas methods with our data. Below, the ```decribe()``` method is used to easily return statistical analysis on a set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_2 = [23,52,62,25,24,22,21,28,32]\n",
    "my_series_2 = pd.Series(my_data_2)\n",
    "# PRINT OUT MY_SERIES-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THE DESCRIBE() METHOD WITH MY_SERIES_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the datatype for the \"describe\" result is different -that is because this is Series of it's own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "The second major Pandas datatype is the DataFrame. A DataFrame is a tabular (table-like), 2-dimensional(i.e., rows and columns) object that is in many ways the central part of the pandas library. DataFrames are both indexed, like Series, and labeled. The index corresponds to the rows of the DataFrame while the labels correspond to the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniitalizing a DataFrame using the first Series we created.\n",
    "df = pd.DataFrame(my_series)\n",
    "\n",
    "# Adding the second Series to the DataFrame\n",
    "df[\"My Numbers\"] = my_series_2\n",
    "\n",
    "# Viewing the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame features the same index as the series used to create it's columns. Within the DataFrame, every row and column that makes it up is in fact its own Pandas Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "There are numerous ways to create data frames conveniently built into Pandas depending on the structure of our target data. The following are just a few of the most common:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A list of dictionaries\n",
    "This method is ideal for creating dictionaries from data generated within a loop, such as iterating over data from an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of dictionaries\n",
    "my_dict_1 = {\"Letters\": \"a\", \"Num_1\": 23, \"Num_2\": 2}\n",
    "my_dict_2 = {\"Letters\": \"b\", \"Num_1\": 26, \"Num_2\": 3}\n",
    "my_dict_3 = {\"Letters\": \"c\", \"Num_1\": 32, \"Num_2\": 2}\n",
    "my_dict_4 = {\"Letters\": \"d\", \"Num_1\": 21, \"Num_2\": 4}\n",
    "\n",
    "# Add all of these dictionaries to a list\n",
    "my_list = [my_dict_1, my_dict_2, my_dict_3, my_dict_4]\n",
    "\n",
    "# Then convert that into a DataFrame\n",
    "# CONVERT THE LIST TO A DATAFRAME HERE\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dictionary of lists\n",
    "A dictionary of lists is a quick way to hand-write small data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of lists\n",
    "column_a = [\"a\",\"b\",\"c\",\"d\"]\n",
    "column_b = [23,26,32,21]\n",
    "column_c = [2,3,2,4]\n",
    "\n",
    "# Insert them into a dictionary\n",
    "my_dict = {\"Letters\": column_a, \"Num_1\": column_b, \"Num_2\": column_c}\n",
    "\n",
    "# Then convert that into a DataFrame\n",
    "# CONVERT THE DICTIONARY TO A DATAFRAME HERE\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a SQL database\n",
    "Data can be read directly from SQL databases using Pandas. For this example, we will use sqlalchemy to quickly build a SQL database from a SQLite file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing additional dependencies\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Path to SQLite file\n",
    "database_path = \"data_sources/Census_Data.sqlite\"\n",
    "\n",
    "# Creating the SQL database\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "\n",
    "# Establisting a connection to our database\n",
    "conn = engine.connect()\n",
    "\n",
    "# Using pandas to read data out of SQL\n",
    "census_data = # USE PANDAS TO CONNECT TO THE SQL DATABASE\n",
    "\n",
    "# Because this DataFrame is so large, we will use the head() method to print out the top 5 entries.\n",
    "# USE THE HEAD() METHOD TO VIEW DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to shutdown the database when we are done with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping a table\n",
    "You can scrape table elements directly from HTML using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the URL to scrape from\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_the_highest_major_summits_of_North_America\"\n",
    "\n",
    "# Converting all table elements from the page into DataFrames. This method returns a list of DataFrames from the URL.\n",
    "mountains_table_list = # USE PANDAS TO SCRAPE THE URL FOR TABLES\n",
    "\n",
    "# Parsing through the list to find the table we want\n",
    "mountains_table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the table we want is the second entry in the list of tables, so we will save it and print its head.\n",
    "mountains_df = # INPUT THE CORRECT TABLE HERE\n",
    "mountains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a CSV\n",
    "One of the most common ways to ingress data using Pandas, the humble CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CSV path\n",
    "path = \"data_sources/Census_Data.csv\"\n",
    "\n",
    "# Creating a DataFrame from the CSV\n",
    "census_data = # USE PANDAS TO READ THE CSV\n",
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from a DataFrame\n",
    "Now that we have our data in a DataFrame format, we need to be able to use it. The first thing we will want to learn to that end is how to read data back out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "We can parse a DataFrame similar to how we might a list our dictionary, selecting the column by using its label as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Letters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further drill down using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A SINGLE CELL USING INDEXING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using iloc[ ]\n",
    "Another option is to navigate the DataFrame entirely by numbers using ```iloc[ ]```. We can retrieve a whole column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 0] # Note the format here, [rows, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A SINGLE CELL USING ILOC[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using loc[ ]\n",
    "Thes do not always work well because of the way indexes can be set in DataFrames and generally appear cluttered or as a mass of incomprehensible numbers. To get around this, we can use the ```loc[ ]``` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Letters')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is no numerical index for us to gauge what item we want with, instead we will use loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A SINGLE CELL USING LOC[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index for the mountains DataFrame to the rank column\n",
    "mountains_df = mountains_df.set_index('Rank')\n",
    "\n",
    "# Use lambda functions to convert the Prominence, Elevation, and Isolation to numerical datatypes\n",
    "def convert_ht(x):\n",
    "    height = x.replace(\",\",\"\").replace(\"\\xa0ft\",\"\")\n",
    "    return int(height)\n",
    "\n",
    "def convert_mi(x):\n",
    "    if isinstance(x, str):\n",
    "        x = float(x.replace(\",\",\"\").replace(\"\\xa0mi\",\"\"))\n",
    "    return x\n",
    "\n",
    "mountains_df['Elevation'] = mountains_df['Elevation'].apply(lambda x:convert_ht(x))\n",
    "mountains_df['Prominence'] = mountains_df['Prominence'].apply(lambda x:convert_ht(x))\n",
    "mountains_df['Isolation'] = mountains_df['Isolation'].apply(lambda x:convert_mi(x))\n",
    "mountains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read with one condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Boolean Series\n",
    "mountains_df['Region'] == \"Alaska\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Boolean Series as a key to output data\n",
    "mountains_df[mountains_df['Region'] == \"Alaska\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also parse a DataFrame using multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSE THE DATAFRAME FOR ALASKAN MOUNTAINS TALLER THAN 15,000 FT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation in Pandas\n",
    "Now that we know how to view our data, we can begin manipulating it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop\n",
    "To remove unnecessary data elements, we can use the ```drop()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the Location column\n",
    "mountains_df.drop(columns=\"Location\",inplace=True)\n",
    "mountains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DropNA\n",
    "We can remove data elements from our DataFrame that contain empty cells using the ```dropna()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use .info() to see what columns have null values\n",
    "mountains_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .drop() to remove rows with empty cells\n",
    "mountains_df.dropna(how=\"any\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At and Iat\n",
    "The ```at[ ]``` and ```iat[ ]``` are similiar to ```loc[ ]``` and ```iloc[ ]```, but instead of viewing the data, they allow us to manipulate it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[\"a\",\"Num_2\"] = 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0,1] = 2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append\n",
    "Append is a method for combining two DataFrames to create a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"Letters\": [\"e\",\"f\",\"g\"], \"Num_1\": [20,23,24], \"Num_2\": [2,1,3]}\n",
    "df2 = pd.DataFrame(my_dict).set_index(\"Letters\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = # APPEND DF2 TO DF\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "Join also combines DataFrames, but merges them along the lateral dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"Letters\": [\"a\",\"b\",\"c\"], \"Num_1\": [14,13,14], \"Num_2\": [7,10,13]}\n",
    "df = pd.DataFrame(my_dict).set_index(\"Letters\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"Letters\": [\"a\",\"b\",\"c\"], \"Num_3\": [20,23,24], \"Num_4\": [2,1,3]}\n",
    "df2 = pd.DataFrame(my_dict).set_index(\"Letters\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = # JOIN THE TWO DATA FRAMES TOGETHER\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountains_df.groupby(\"Region\").mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
